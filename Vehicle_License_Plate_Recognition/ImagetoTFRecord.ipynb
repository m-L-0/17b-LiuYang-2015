{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "INFO:tensorflow:Error reported to Coordinator: <class 'tensorflow.python.framework.errors_impl.InvalidArgumentError'>, Input to reshape is a tensor with 2160 values, but the requested shape has 1152\n",
      "\t [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](DecodeRaw, Reshape/shape)]]\n",
      "done!\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Input to reshape is a tensor with 2160 values, but the requested shape has 1152\n\t [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](DecodeRaw, Reshape/shape)]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-4f1bb157fe1e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_and_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'plate_train.tfrecords'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-25-4f1bb157fe1e>\u001b[0m in \u001b[0;36mread_and_decode\u001b[0;34m(tfrecords_file, batch_size)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0mcoord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mw\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# print(s)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env/lib/python3.6/site-packages/tensorflow/python/training/coordinator.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, threads, stop_grace_period_secs, ignore_live_threads)\u001b[0m\n\u001b[1;32m    387\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_registered_threads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m         \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exc_info_to_raise\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0mstragglers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mignore_live_threads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env/lib/python3.6/site-packages/tensorflow/python/training/queue_runner_impl.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, sess, enqueue_op, coord)\u001b[0m\n\u001b[1;32m    236\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m           \u001b[0menqueue_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_queue_closed_exception_types\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=catching-non-exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m           \u001b[0;31m# This exception indicates that a queue was closed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_single_operation_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1229\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1230\u001b[0m           tf_session.TF_Run(self._session, None, {}, [],\n\u001b[0;32m-> 1231\u001b[0;31m                             target_list_as_strings, status, None)\n\u001b[0m\u001b[1;32m   1232\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_single_operation_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/env/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Input to reshape is a tensor with 2160 values, but the requested shape has 1152\n\t [[Node: Reshape = Reshape[T=DT_UINT8, Tshape=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](DecodeRaw, Reshape/shape)]]"
     ]
    }
   ],
   "source": [
    "'''''\n",
    "为实现车牌数字字母字符识别(10个数字+24个字母为数据集)\n",
    "\n",
    "'''''\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def read_and_decode(tfrecords_file, batch_size=25):\n",
    "    '''read and decode tfrecord file, generate (image, label) batches\n",
    "    Args:\n",
    "        tfrecords_file: the directory of tfrecord file\n",
    "        batch_size: number of images in each batch\n",
    "    Returns:\n",
    "        image: 4D tensor - [batch_size, width, height, channel]\n",
    "        label: 1D tensor - [batch_size]\n",
    "    '''\n",
    "    print('start')\n",
    "    batch_size = batch_size\n",
    "    filename_queue = tf.train.string_input_producerroducer([tfrecords_file])\n",
    "    \n",
    "    reader = tf.TFRecordReader()\n",
    "    _, serialized_example = reader.read(filename_queue)\n",
    "    img_features = tf.parse_single_example(\n",
    "                                        serialized_example,\n",
    "                                        features={\n",
    "                                               'label': tf.FixedLenFeature([], tf.int64),\n",
    "                                               'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                                               })\n",
    "    image = tf.decode_raw(img_features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, [20, 36])\n",
    "    image = tf.cast(image,tf.float32)*(1./255)\n",
    "    label = tf.cast(img_features['label'], tf.int32)    \n",
    "    image_batch, label_batch = tf.train.batch([image,label], batch_size = batch_size, capacity=10000)\n",
    "    with tf.Session() as sess:\n",
    "        i = 0\n",
    "\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord)\n",
    "        \n",
    "        try:\n",
    "            while not coord.should_stop() and i < 1:\n",
    "                # just plot one batch size \n",
    "                \n",
    "                image, label = sess.run([image_batch, label_batch])\n",
    "                #plot_images(image, label)\n",
    "                # image = image.reshape(784)\n",
    "                i += 1\n",
    "                \n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print('done!')\n",
    "        finally:\n",
    "            coord.request_stop()\n",
    "    coord.join(threads)\n",
    "    w ,= label.shape\n",
    "    # print(s)\n",
    "    b = np.empty((w,36))\n",
    "    for i in range(w):\n",
    "        for j in range(36):\n",
    "            if j==label[i]:\n",
    "                b[i][j]=1.\n",
    "            else:\n",
    "                b[i][j]=0.\n",
    "    \n",
    "    s,d,f=image.shape\n",
    "    images=np.empty((s,d*f))\n",
    "    for q in range(s):\n",
    "        c=image[q]\n",
    "        images[q]=c.reshape(d*f)\n",
    "        # image=images\n",
    "        print('ok')\n",
    "    return images, b\n",
    "\n",
    "\n",
    "\n",
    "[X_train, y_train] = read_and_decode('plate_train.tfrecords', 50)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "[X_val, y_val] = read_and_decode('plate_validation.tfrecords', 3475)\n",
    "\n",
    "\n",
    "\n",
    "def chooseone(image, label, batchsize):\n",
    "    im = np.empty((batchsize, 2160))\n",
    "    la = np.empty((batchsize, 36))\n",
    "    for i in range(batchsize):\n",
    "        a = random.randint(0, 3474)\n",
    "        im[i] = image[a]\n",
    "        la[i] = label[a]\n",
    "    return im, la\n",
    "\n",
    "\n",
    "# 权值初始化\n",
    "def weight_variable(shape):\n",
    "    # 用正态分布来初始化权值\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "def bias_variable(shape):\n",
    "    # 本例中用relu激活函数，所以用一个很小的正偏置较好\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 定义卷积层\n",
    "def conv2d(x, W):\n",
    "    # 默认 strides[0]=strides[3]=1, strides[1]为x方向步长，strides[2]为y方向步长\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "\n",
    "# pooling 层\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "\n",
    "X_ = tf.placeholder(tf.float32, [None, 2160])\n",
    "y_ = tf.placeholder(tf.float32, [None, 36])\n",
    "\n",
    "# 把X转为卷积所需要的形式\n",
    "X = tf.reshape(X_, [-1, 48, 24, 1])\n",
    "# 第一层卷积：3×3×1卷积核32个 [3，3，1，32],h_conv1.shape=[-1, 48, 24, 32],学习32种特征\n",
    "W_conv1 = weight_variable([3, 3, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(X, W_conv1) + b_conv1)\n",
    "\n",
    "# 第一个pooling 层[-1, 48, 24, 32]->[-1, 24, 12, 32]\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# 第二层卷积：5×5×32卷积核64个 [3，3，32，64],h_conv2.shape=[-1, 24, 12, 64]\n",
    "W_conv2 = weight_variable([3, 3, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "# 第二个pooling 层,[-1, 24, 12, 64]->[-1, 14, 6, 64] \n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# \n",
    "W_conv3 = weight_variable([3, 3, 64, 96])\n",
    "b_conv3 = bias_variable([96])\n",
    "h_conv3 = tf.nn.relu(conv2d(h_pool2, W_conv3) + b_conv3)\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "# flatten层，[-1, 6, 3, 96]->[-1, 6*3*96],即每个样本得到一个6*3*96维的样本\n",
    "h_pool2_flat = tf.reshape(h_pool3, [-1, 6*3*96])\n",
    "\n",
    "# fc1\n",
    "W_fc1 = weight_variable([6*3*96, 512])\n",
    "b_fc1 = bias_variable([512])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# dropout: 输出的维度和h_fc1一样，只是随机部分值被值为零\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# 输出层\n",
    "W_fc2 = weight_variable([512, 36])\n",
    "b_fc2 = bias_variable([36])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "\n",
    "# 1.损失函数：cross_entropy\n",
    "cross_entropy = -tf.reduce_sum(y_ * tf.log(y_conv))\n",
    "# 2.优化函数：AdamOptimizer\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "\n",
    "# 3.预测准确结果统计\n",
    "# 预测值中最大值（１）即分类结果，是否等于原始标签中的（１）的位置。argmax()取最大值所在的下标\n",
    "z = tf.argmax(y_conv, 1)\n",
    "q = tf.arg_max(y_, 1)\n",
    "correct_prediction = tf.equal(z, q)  \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "test_acc_sum = tf.Variable(0.0)\n",
    "batch_acc = tf.placeholder(tf.float32)\n",
    "new_test_acc_sum = tf.add(test_acc_sum, batch_acc)\n",
    "update = tf.assign(test_acc_sum, new_test_acc_sum)\n",
    "saver = tf.train.Saver(max_to_keep=2)\n",
    "# 定义了变量必须要初始化，或者下面形式\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer = tf.summary.FileWriter(FLAGS.my_list, sess.graph)\n",
    "\n",
    "    ckpt = tf.train.latest_checkpoint(FLAGS.my_list)\n",
    "    step = 0\n",
    "    if ckpt:\n",
    "        check_point_path = '/home/r/mycar/cnn'  # 保存好模型的文件路径\n",
    "        ckpt = tf.train.get_checkpoint_state(checkpoint_dir=check_point_path)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    Y = np.zeros(3000)\n",
    "    X_batch, y_batch = chooseone(X_val, y_val, 3000)\n",
    "    Ytemp = y_conv.eval(feed_dict={X_: X_batch, keep_prob: 1.0})\n",
    "    for i in range(3000):\n",
    "        Y[i] = np.argmax(Ytemp[i])\n",
    "    print(\"验证集正确率为 %g\" % accuracy.eval(feed_dict={X_: X_batch, y_: y_batch, keep_prob: 1.0}))\n",
    "\n",
    "\n",
    "for j in range(36):\n",
    "    k = 0\n",
    "    l = 0\n",
    "    for i in range(3000):\n",
    "        if np.argmax(y_batch[i]) == j:\n",
    "            k = k+1\n",
    "            if Y[i] == j:\n",
    "                if np.argmax(y_batch[i]) == Y[i]:\n",
    "                    l = l+1\n",
    "    if j < 26:\n",
    "        a = str(chr(ord('A') + j))\n",
    "    elif j > 25:\n",
    "        a = str(chr(ord('0') + j - 26))\n",
    "    if k==0:\n",
    "        print('样本中无%s 无法计算' % a)\n",
    "    else:\n",
    "        print('%s召回率为%g' % (a, (l/k)))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
